# ğŸ§  Lab â€“ Hidden Markov Models (HMM)

## ğŸ“˜ Description
Ce notebook fait partie du cours **Machine Learning 2** (Degree in Data Science and Engineering, Fall 2024).  
Il explore en profondeur les **Hidden Markov Models (HMM)**, un modÃ¨le probabiliste sÃ©quentiel utilisÃ© pour modÃ©liser des donnÃ©es temporelles ou symboliques.  
Les exemples et exercices ont Ã©tÃ© adaptÃ©s par *Jose Manuel de Frutos Porras* et *David MartÃ­nez Rubio* Ã  partir du travail de *Ignacio Peis* (Dept. of Signal Processing and Communications).

---

## ğŸ§© Contenu principal

### 1. Introduction  
PrÃ©sentation des **Markov Models** et introduction des **variables latentes** pour former un modÃ¨le cachÃ© (HMM).  

### 2. Hidden Markov Models  
- DÃ©finition formelle du modÃ¨le : Ã©tats cachÃ©s, observations, probabilitÃ©s de transition et dâ€™Ã©mission.  
- SchÃ©ma de la structure probabiliste.  
- Notations :  
  - \( A \): matrice de transition  
  - \( B \): distribution dâ€™Ã©mission  
  - \( \pi \): distribution initiale  

#### 2.1. Inference  
Explication des principaux algorithmes :
- **Forward** : calcul de la probabilitÃ© dâ€™une sÃ©quence observÃ©e.  
- **Forward-Backward** : estimation des marges lissÃ©es.  
- **Viterbi** : recherche de la sÃ©quence dâ€™Ã©tats la plus probable.

#### 2.2. Learning â€“ Baum-Welch Algorithm  
Apprentissage des paramÃ¨tres \( A, B, \pi \) via lâ€™algorithme **EM** adaptÃ© aux HMM :
- Ã‰tape **E** : calcul des espÃ©rances (Î³, Î¾).  
- Ã‰tape **M** : mise Ã  jour des paramÃ¨tres du modÃ¨le.  
- Cas **gaussien** et **discret** abordÃ©s.

#### 2.3. Fully Observed HMMs  
Version simplifiÃ©e oÃ¹ les Ã©tats sont connus â€” calcul direct du maximum de vraisemblance.

#### 2.4. HMMs avec `hmmlearn`  
PrÃ©sentation de la bibliothÃ¨que Python [`hmmlearn`](https://hmmlearn.readthedocs.io) : crÃ©ation, entraÃ®nement et gÃ©nÃ©ration de sÃ©quences HMM.

---

## ğŸ§ª 3. ExpÃ©rimentations â€“ Human Activity Recognition (HAR)
Application pratique des HMM Ã  la **reconnaissance dâ€™activitÃ©s humaines** Ã  partir de donnÃ©es capteurs (base *DaLiAc*).  
- PrÃ©traitement des donnÃ©es (fenÃªtrage, extraction de moyennes/Ã©carts types).  
- Apprentissage dâ€™un HMM gaussien avec `hmmlearn`.  
- Visualisation de la **matrice de transition** \( A \) et interprÃ©tation des activitÃ©s.  

---

## âš™ï¸ Librairies utilisÃ©es
- `numpy`  
- `pandas`  
- `matplotlib`  
- `scikit-learn`  
- `hmmlearn`

---

## ğŸ¯ Objectif
- Comprendre la structure et le fonctionnement des HMM.  
- ImplÃ©menter les algorithmes dâ€™infÃ©rence et dâ€™apprentissage.  
- Appliquer un HMM Ã  des donnÃ©es rÃ©elles (reconnaissance dâ€™activitÃ©).

---
